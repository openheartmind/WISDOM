# ACX Grant

Time tracking:

[_Intro post_](https://www.astralcodexten.com/p/apply-for-an-acx-grant-2024)

[_application form_](https://docs.google.com/forms/d/e/1FAIpQLSc6vmem8-XfhVkMde3PCyysAS_bwBImk3H9iJo0S1OsqfUHWg/viewform)

  

# _Short one-sentence description of your proposed project_

_Max length 300 characters. Examples:_

_\- Create a foundation to build wells in Kenya_

_\- Do preliminary research on X-312, a promising new diabetes drug_

_\- Support a political campaign to get Wal-Mart to stop eating puppies_

###   

### Develop a universally applicable and standardised framework for recognising and rewarding contributions to the commons

  

# _Longer description of your proposed project_

_Max 5000 characters_

  

The Problem:

Recognition and reward are central challenges in collaborative efforts, especially in commons-oriented fields like open source and academia. An ideal system should capture, recognise and reward the unique qualities of every contribution, fostering trust and incentivising quality contributions.

  

Recognition and reward systems often fall short, however, failing to encompass the full range of contributions (e.g., code in academia), recognise their unique qualities (e.g. replicability), or reward contributors fairly (e.g. open source).

  

Furthermore, the diversity of systems creates an even more extensive optimisation problem: aligned communities may forgo cooperation due to incompatible systems. Examples abound in the open science space, where aligned projects (e.g. preprint-review platforms) compete for scarce resources (e.g. funding, people), instead of cooperating.

  

Our proposal:

We propose to develop a universally applicable, standardised framework for recognising and rewarding contributions, thereby fostering cooperation. Our framework builds on open evaluation models for academia (e.g. Kriegeskorte, 2012), where crowd-ratings can vary on multiple dimensions, including but not limited to a 'primary' dimension. In what follows, I will outline our core model in which the primary dimension is "Gratitude", selected both for its broad applicability to diverse contributions and the neuropsychological benefits of a regular gratitude practice.

  

Our model uses pairwise comparisons (e.g., "Which of these two contributions are you most grateful for?") to generate ratings at the crowd-level. Pairwise comparisons are a quick, simple and user-friendly review protocol, ensuring that diverse people can contribute data, regardless of expertise or technical prowess.

  

Pairwise comparisons are also relatively uniform across use cases, meaning that we can use them as a 'standard unit' of contribution. Reviewers are rewarded with one token for every pairwise comparison they complete, representing a single 'unit of gratitude' for their contribution. 

  

Other contributions are then scaled relative to this standard unit. This is achieved by including pairwise comparisons in the overall contribution set and submitting them for 'meta-review. A qualified reviewer might be given a pair of contributions to review, one of which is itself a review contribution (e.g. 32 pairwise comparisons). By including a range of pairwise comparisons (e.g. 32, 64, 128), we can fit a function to the resulting votes and extrapolate values for all other contributions, giving us a relative level of collective gratitude for every single contribution, given in terms of pairwise comparisons (see 'algorithm' tab in our prototype dataset: [http://tiny.cc/tinyOHMresults](http://tiny.cc/tinyOHMresults))

  

Contributors can then be automatically rewarded for all of their contributions. Communities might also agree to subtract common costs (e.g. the average cost of an event in tokens), leaving a balance that reflects each contributor’s total energetic exchange with the community (see 'Summary' tab, 'Reward' column, in our prototype dataset). 

  

By measuring contributions over time, we can also identify key contributors (e.g. reliable reviewers, experts), who might then be given more rewards for their reviews or higher weights in governance votes (see 'Respect').

  

Finally, contributors can give their tokens to other people who they wish to thank in turn, or  exchanging them for community resources (e.g. money; see "Receive"). Communities with surplus funds might establish grant programs, with grants awarded based on a combination of verified expertise ('Respect') and prospective votes, and with grantees tracking their contributions over time.

  

Conclusion:

The above model is flexible, allowing custom dimensions to capture the unique strengths of contributions and contributors. These ratings could create a multidimensional, hierarchical information landscape that can be filtered for each user’s needs. It could also serve as a high-signal training ground for AI, while retaining collective control and value within the community.

  

Our model is scaleable and autonomous, making it a candidate for disrupting antiquated institutions like academia and politics. Reviews are inclusive and rewarded, providing a needed incentive where existing peer review and participatory democracy platforms have fallen short. Reviews are also inclusive, guarding against replication of systemic biases we see elsewhere (e.g. decentralised networks). 

  

Finally, our core model is simple and adaptable, making it suitable for diverse communities (e.g. open science, open source, charities, artists, etc) who can then agree to share value across their borders. Contributors might build up tokens in one community (e.g. open source) and spend them in another (e.g. arts festivals), or express gratitude for an entire project (e.g. a core resource), with tokens being split automatically between contributors.

  

# _Describe why you think you're qualified to work on this_

_Include references if you have them, but don't worry if you don't. Max 5000 characters_

  

For the past two years I’ve been leading Open Heart + Mind (OHM), a registered charity that hosts gift-based gatherings and uses these to prototype new models for community organisation. The framework here is the result of iteration over multiple OHM gatherings and reviews, having evolved from my initial scholarly publishing model to a general-purpose model for diverse communities.

  

So, the main reason I think I'm qualified to work on this is, well, I already am. But I also feel that the two decades prior to founding OHM have prepared me well for the journey ahead.

  

Design:

My first career was in architecture, but I became disillusioned with the industry and decided to travel the world instead. Today, I’m repurposing my creative problem solving skills to design a new ‘game’ for society, from the ground up.

  

Meditation:

I discovered a passion for the mind at a meditation retreat in Thailand and resolved to explore consciousness from all angles, objective and subjective. Meditation has since lead me to other mindfulness practices (e.g. yoga, dance), all of which help me to maintain balance as I manage OHM. 

  

Psychology:

I studied psychology, graduating top of both my undergraduate degree and honours thesis ([https://coopersmout.com/awards](https://coopersmout.com/awards)). Despite these accolades, the paper that resulted from this work was reviewed and rejected by multiple journals, wasting everyone’s time and delaying publication by two years. Even worse, I felt pressured to tell a particular ‘type’ of story (e.g., novel, significant) and was disheartened to realise that the system actually incentivises bias, gaming and questionable research practices. Since then, I’ve been using my knowledge of psychology to design new models that incentivise mutually beneficial behaviours and reward honesty.

  

Neuroscience:

I completed a PhD in the neuroscience of visual awareness, winning the Dean's Award and several other prizes ([https://coopersmout.com/awards](https://coopersmout.com/awards/)). My presentations ([https://coopersmout.com/talks](https://coopersmout.com/talks/)) and publications ([https://orcid.org/0000-0003-1144-3272](https://orcid.org/0000-0003-1144-3272)) have taught me how to communicate complex ideas to broad audiences. At OHM, I’m using my experimental skills to design and conduct reviews and I expect my big data skills (machine learning, multivariate analysis, computational modelling) will become increasingly valuable as our system matures.

  

Free Our Knowledge:

During my PhD, I founded Free Our Knowledge (FOK) to address the collective action problem in academia and organise a critical mass of support for underused open science journals and practices ([www.freeourknowledge.org](http://www.freeourknowledge.org/)). I made lots of mistakes and learned a lot, embracing entrepreneurialism and a lean startup methodology. I completed the Open Life Science Leaders program and learned how to manage open source projects. Now that we have a working prototype for OHM, I plan to leverage FOK’s network to develop collaborations and test my hypothesis that our model will facilitate cooperation between projects.

  

Poker:

After my PhD I went ‘rogue’, playing poker to fund myself rather than compete against aligned projects. I’ve had a few big wins and used these to support my basic needs and projects since ([https://coopersmout.com/poker](https://coopersmout.com/poker/)). Poker has taught me how to embrace uncertainty, balance information streams and make calculated risks. It’s also added significant variance to my financial and mental stability, however, and so I’m now looking for a more stable income moving forward.

Compassion:

My other reason for leaving academia was to recover from burnout, caused by environmental and personal factors in my attempt to ‘win’ the game of academia. My subsequent recovery has been difficult but rewarding, as it equipped me with valuable tools (e.g., self-compassion) and the capacity to empathise with the suffering of others.

  

Community:

My healing journey brought me to festivals, where I’ve connected with a network of artists, musicians, healers and festival attendees. COVID taught me that this community and my scientific community were aligned in intentions but not opinions, and so I organised a gift-based festival for these communities to connect and learn from one another. I then realised we could use festival contributions as an analogy for research contributions in my scholarly publishing model, and thus OHM was born. In the two years since, I’ve been developing and prototyping the model, while learning to build community, host gatherings, administer a charity and manage the development of our bespoke app.

  

Metascience:

Last month I presented OHM at the Association for Interdisciplinary Metaresearch & Open Science conference ([tiny.cc/ohmAIMOS23vid](http://tiny.cc/ohmAIMOS23vid)) and we're now collaborating to develop another prototype, in which we will recognise and reward contributions to the AIMOS conference itself. I expect this will be the first of many such collaborations, as we develop the model and establish a network of aligned communities speaking the same fundamental language.

  

  

_Other ways I can learn about you_

_EG your Twitter handle, your ACX commenter handle, links to things you've written online. Partly this is just to prove you're a real person. If you don't have anything like this, that's fine._

  

Personal website (blog needs a serious update): [https://coopersmout.com/](https://coopersmout.com/)

Publications: [https://orcid.org/0000-0003-1144-3272](https://orcid.org/0000-0003-1144-3272)

Twitter: [https://twitter.com/coopsmout](https://twitter.com/coopsmout)

Facebook: [https://www.facebook.com/cooper.smout](https://www.facebook.com/cooper.smout)

Poker results: [https://pokerdb.thehendonmob.com/player.php?a=r&n=585943](https://pokerdb.thehendonmob.com/player.php?a=r&n=585943)

Free Our Knowledge: [https://freeourknowledge.org/](https://freeourknowledge.org/)

  

  

_How much money do you need?_

_Feel free to give either a simple number, or a range, a complicated answer, or a list of what could be done with how much_

  

We would happily receive any amount you can give us. Our system is designed to handle all contributions, big and small, and distribute them to contributors, so our impact would scale with whatever you can afford.

  

We've spent part our first major donation ($50k) on gatherings and admin (see [https://opencollective.com/open-heart-mind](https://opencollective.com/open-heart-mind)), with the remainder earmarked for rewarding contributions to date, via our system (apparently this is called dogfooding, though I've no idea why). Any amount you donate would serve to incentivise future contributions and collaborations with aligned communities moving forward (e.g., by designating a pool of money to develop a prototype with another community, or to reward contributors to our app). If you were to give us $100k (which seems around your upper limit), it would show that we are growing while also giving us a chance to progressively scale with larger donations over time.

  

I'm also interested in exploring our system as an automated grants/reward system, for example collaborating with existing communities to recognise and reward core contributors retrospectively, or using our system to track new projects and automatically reward contributors (e.g., ACX grant recipients). In the future, I anticipate our system evolving into an automated grants program, where anyone can drop money into it, nominate their preferred field of interest, and the money gets automatically distributed based on crowd votes and other metrics within the system. If any of this sounds useful to your current or future grants, I'd love to discuss.

  

_Links to any supporting documents or information_

_You don't need to include anything here if you don't want to._

_Your answer_

  

Readme: [http://tiny.cc/ohmreadme](http://tiny.cc/ohmreadme)

Socials: [http://linktr.ee/openheartmind](http://linktr.ee/openheartmind)

Facebook group: [https://www.facebook.com/groups/ohmcollective](https://www.facebook.com/groups/ohmcollective)

Website (needs an update): [https://openheartmind.org](https://openheartmind.org/)

Prototype data, analysis and results, from one of our gatherings: [https://tiny.cc/tinyOHMresults](https://tiny.cc/tinyOHMresults)

AIMOS conference presentation: [https://tiny.cc/ohmAIMOS23vid](https://tiny.cc/ohmAIMOS23vid)

Charity registration: [https://www.acnc.gov.au/charity/charities/d6e0c1b9-3aaf-e811-a960-000d3ad24282/documents/f5cf0e8f-81eb-ec11-bb3d-002248944e6d](https://www.acnc.gov.au/charity/charities/d6e0c1b9-3aaf-e811-a960-000d3ad24282/documents/f5cf0e8f-81eb-ec11-bb3d-002248944e6d)

  

  

_Estimate your probability of succeeding if you get the amount of money you asked for_

_Include your definition of "success" if it isn't obvious. Feel free to give a low number here, I understand that long shots at ambitious goals are also valuable._

  

My definition of success includes learning from failure, so I guess in that sense is 100%. Beyond that, it's difficult to put a number to this because it depends on what target we're talking about.

  

If the target is improving collaboration within communities, I'd say this is 100% because we're already doing this at OHM. Improving collaboration within other communities depends on whether they wish to adopt our system, which is difficult for me to estimate at this stage (though there seems to be interest in the AIMOS community, based on our new collaboration). Improving collaboration between communities is also difficult to estimate, because it depends on the degree to which they adopt our system and recognise other, aligned communities within our network. But discussions from project leaders in other communities lead me to believe there is great desire for something like this to help us all get on the same page and working toward a better future, together.

  

As for academia, I'm confident that this model, or something like it, will play a part in reforming academia. For me, it's not a matter of if, but when -- there are simply too many problems and inefficiencies with the current model for it to last much longer. The timescale of that disruption depends on how much support there is for systemic alternatives, like what we propose here. It might be that our model is not quite the right model and requires some extra features I haven't thought of. It might be that I'm not the right person to bring it to fruition. I do believe that our model is unique and novel, however, and so even if it is not the final model that causes disruption, it may inspire another model that does. Whether or not that future model is developed with OHM or separately, I would still consider it a success.

  

I can also see our model playing a role in disrupting other institutions, like politics through participatory democracy. Here there's a lot more variance because I'm not as familiar with these systems. Similar to academia, however, I know there's similar frustration with the inefficiencies of these systems and so there's a clear hunger for change.

  

If you're looking for a percentage to calculate expected value, I'm sorry to disappoint. But I would also suggest it's near-impossible to calculate the potential upsides of the type of widespread, systemic change I'm proposing here. The best answer I can give that even if the percentage likelihood is ridiculously small, it would still be a gamble I'd take at the poker table.

  

  

_What's the most likely counterfactual if this doesn't get ACXG funding?_

_Are you applying to other grants programs? Will you do a smaller version? Will it not happen?_

  

If we don't get ACXG funding I'll look into other options. To be honest, this is the first grant I'm applying to for OHM (our first donor found me via FOK, not the other way around) and it seemed like auspicious timing after just presenting our prototype at the AIMOS conference. If we're not successful here I'll look into other options, potentially some of those you mentioned in last year's grants retrospective. I'll be honest though, I'm an incredibly slow and meticulous writer (50+ hours time tracked for this grant application in our transparent workspace: [https://sharing.clickup.com/36615879/t/h/86cu75qh9/4RJ7ZFDVKJ7Y78X](https://sharing.clickup.com/36615879/t/h/86cu75qh9/4RJ7ZFDVKJ7Y78X)), so preparing another grant application would take me considerable time that I'd much rather put into developing our system.

  

I'm also looking for aligned individuals and communities to collaborate with, and suspect there's more potential synergy with someone who gives away their own money and experiments with a microgrants program than a charity board or other traditional funding mechanisms (but again, I haven't looked into this). Whether you fund OHM or not, I'm happy to chat about collaborations and potential synergies, e.g., with this microgrants program.

  

  

_Can I share your proposal, non-publicly, with other interested parties?_

_This might involve passing it around to other potential donors and nonprofits looking for projects to fund. This requires zero work on your part and greatly increases the chance that it gets funded, I strongly recommend saying yes._

  

_I'm including an "Other" option for you to list conditions you want followed, but keep in mind I expect to be dealing with 500 grants and if you make this at all complicated I will probably just default to not doing this. If your conditions are minor and unimportant, I strongly recommend just clicking YES._

  

  

_Anything else I should know?_

_Feedback about this process, etc._

  

Not that I can think of, but please get in touch if anything is unclear. I also just wanted to say thanks for doing what you're doing, I resonate with your attitude of putting your money where your mouth is and learning by doing. I look forward to hearing your feedback.

# discarded content

According to motivation theory, individuals are maximally motivated when their rewards seem fair in relation to (a) their own contributions, and (b) rewards given to other people.

  

Existing recognition and reward systems tend to fall short in one or more of the three key stages (communication, evaluation, reward). Academia, for example, suffers from an undue focus on journal articles at the expense of other contributions (e.g., preprints, code, data), coupled with inappropriate metrics (e.g., journal impact factor) that do not capture the value of individual papers, let alone their unique qualities. Quantitative metrics in the open source movement (e.g., code commits) aim to objectify evaluations, but fail to capture non-coding contributions and may not represent the true value of individual contributions. In decentralised networks, tokenomics are proposed as a democratic solution to the evaluation problem, but typically favour early-adopters and fail to capture non-monetary contributions.

  

An ideal recognition and reward system should serve three main functions: capture/communicate the full range of contributions, evaluate contributions with respect to their unique qualities, and reward contributors appropriately (monetarily or otherwise). Of these three functions, the second (evaluation) is the trickiest, not least because 'value' is a subjective phenomenon that can vary over time and different contexts.

  

Existing solutions to this problem are diverse, spanning quantitative metrics like code commits in open source software, to peer review processes in academia and tokenomics in decentralized networks. The benefit of such diverse approaches is that they can be customised to meet the needs of each community (whether they actually do is a different story); the downside is that diverse but aligned communities may fail to communicate recognition or share rewards beyond their borders, limiting cooperation toward their mutual goals.

  

Most communities lack a fair, transparent, autonomous and evidence-based way to quantify the relative value of contributions. Lacking such a mechanism, individuals are often incentivised to act in ways that are sub-optimal for the community and broader public.

  

In academia, for example, the relative value of contributions is often quantified using inappropriate metrics, such as the journal impact factor or H-index, which measure artificial 'prestige' moreso than actual quality (BREMBS). In turn, this leads researchers to pursue suboptimal lines of research, engage in questionable research practices, not share their data or code, salami-slice papers, and continue supporting antiquated journal systems at the cost of free and open alternatives. Clearly, the academic community could benefit from a reliable system to quantify the relative quality of contributions, but as yet the growing number of platforms offering transparent crowd-based ratings remain under-utilised.

  

*   In academia, where the journal impact factor is often used as a (/an unjustified) proxy for quality (BREMBS), researchers may be incentivised to pursue low-risk research, engage in questionable research practices, keep data and code hidden, salami-slice papers, and continue supporting privatised journal systems at the cost of free and open alternatives.
*   In the commercial sector, biased crowd-ratings ([Rocklage, Rucker & Nordgren, 2021](https://www.nature.com/articles/s41562-021-01098-5.epdf?sharing_token=-AOYkwG8aHeBjtpPUNEEDNRgN0jAjWel9jnR3ZoTv0PnmnpyJIIDwy_1BVSz_S2XbvT5Q-9ZZUqvuIfAHa_J7j9-BgRe0UAvlTsbzdJhA6DGMI7EfdyTmFDkZSu1HTZEBGqky_6SiGto071IxeqKQTUyo5o43MZFxCdUynfqM6f1whNNdbZ98xV2idqWuEdXZcqigpA1KV6w3f0gC4RN8jg119UxOpKVEu40PS209EwVrNrOh95lV0xd4Q_R2pDYEeamUA14Uxc1dp4pZKjKZ6RAFpVuauojs-n0lJsihRYxFgThrwvGDK5gFf7Bi3YyKjjWVrnayGGX0wLBzw7bZEuRXRqlQ25N0BssWxjEbFn0jB1G2TGO9n1bTUj-z_y5&tracking_referrer=www.theage.com.au)) can lead consumers to make sub-optimal purchases, rewarding sellers who can drive up positive ratings regardless of actual quality.
*   In the blockchain sector, where any number of DAOs will claim to solve the above problems by offering decentralised voting and attribution,

  

different communities would be free to explore and develop new dimensions in an open-ended way, creating a rich tapestry of evaluative signals that could be filtered according to each users particular needs and preferences.

  

Meta-reviews are necessarily generic during bootstrapping of the system, but can become more targeted when specific instances are available for review (e.g., in the case of gaming or other biases).

  

(lest it spiral into an endless series of meta-reviews, meta-meta-reviews etc.).

  

Here we have presented a minimal framework for evaluating contributions, designed to encourage participation and improve collaboration between commons-oriented communities. Like a mushroom spore that grows into a mycelium network, we envisage this core version growing in a multitude of ways, including the addition of more subtle evaluation layers, like qualitative reviews. New communities who adopt the framework may generate additional insights, which can be shared back with the community. , existing communities All of these future contributions will be fairly recognised and rewarded by the same system we're developing here, potentially using integrating new evaluative signals into ever-more nuanced representations of value
